{
  "1": {
    "inputs": {
      "ckpt_name": "photon_v1.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": ["1", 1]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "3": {
    "inputs": {
      "text": "A photo of Superman in a forest, photorealisitc, cinematic, epic, intricate, dramatic light, forest",
      "clip": ["59", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "INPUT_POSITIVE_TEXT_CLIP Text Encode (Prompt)"
    }
  },
  "4": {
    "inputs": {
      "text": "(low quality, worst quality:1.4), cgi,  text, signature, watermark, extra limbs, ((nipples)), anima, cartoony, 3d, manga, saturated",
      "clip": ["59", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "INPUT_NEGATIVE_TEXT_CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "seed": 1050264163883786,
      "steps": 10,
      "cfg": 2,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": ["20", 0],
      "positive": ["46", 0],
      "negative": ["4", 0],
      "latent_image": ["41", 0]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "16": {
    "inputs": {
      "lora_name": "more_details.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": ["1", 0],
      "clip": ["2", 0]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "19": {
    "inputs": {
      "preset": "FACEID PLUS V2",
      "lora_strength": 1,
      "provider": "CPU",
      "model": ["59", 0]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "20": {
    "inputs": {
      "weight": 1,
      "start_at": 0,
      "end_at": 1,
      "weight_type": "standard",
      "model": ["19", 0],
      "ipadapter": ["19", 1],
      "image": ["37", 0]
    },
    "class_type": "IPAdapter",
    "_meta": {
      "title": "IPAdapter"
    }
  },
  "37": {
    "inputs": {
      "image": "nate.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "INPUT_CAMERA - Load Image"
    }
  },
  "38": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": ["37", 0]
    },
    "class_type": "OpenposePreprocessor",
    "_meta": {
      "title": "OpenPose Pose"
    }
  },
  "39": {
    "inputs": {
      "strength": 1,
      "conditioning": ["3", 0],
      "control_net": ["40", 0],
      "image": ["38", 0]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet (OLD)"
    }
  },
  "40": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_openpose_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "41": {
    "inputs": {
      "pixels": ["37", 0],
      "vae": ["1", 2]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "43": {
    "inputs": {
      "samples": ["5", 0],
      "vae": ["1", 2]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "46": {
    "inputs": {
      "strength": 1,
      "conditioning": ["39", 0],
      "control_net": ["47", 0],
      "image": ["49", 0]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet (OLD)"
    }
  },
  "47": {
    "inputs": {
      "control_net_name": "control_v11f1p_sd15_depth_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "49": {
    "inputs": {
      "resolution": 512,
      "image": ["37", 0]
    },
    "class_type": "Zoe-DepthMapPreprocessor",
    "_meta": {
      "title": "Zoe Depth Map"
    }
  },
  "59": {
    "inputs": {
      "lora_name": "InstantPhotoX3.safetensors",
      "strength_model": 0.25,
      "strength_clip": 1,
      "model": ["16", 0],
      "clip": ["16", 1]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "76": {
    "inputs": {
      "resolution": 666,
      "image": ["43", 0]
    },
    "class_type": "OneFormer-ADE20K-SemSegPreprocessor",
    "_meta": {
      "title": "OneFormer ADE20K Segmentor"
    }
  },
  "84": {
    "inputs": {
      "red": 149,
      "green": 5,
      "blue": 61,
      "threshold": 1,
      "image": ["76", 0]
    },
    "class_type": "MaskFromColor+",
    "_meta": {
      "title": "ðŸ”§ Mask From Color"
    }
  },
  "85": {
    "inputs": {
      "mask": ["84", 0]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "87": {
    "inputs": {
      "r": 255,
      "g": 255,
      "b": 255,
      "image": ["43", 0],
      "mask": ["92", 0]
    },
    "class_type": "Mix Color By Mask",
    "_meta": {
      "title": "Mix Color By Mask"
    }
  },
  "88": {
    "inputs": {
      "image": ["85", 0]
    },
    "class_type": "ImageInvert",
    "_meta": {
      "title": "Invert Image"
    }
  },
  "90": {
    "inputs": {
      "images": ["87", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "92": {
    "inputs": {
      "blur_radius": 2,
      "sigma": 1,
      "image": ["88", 0]
    },
    "class_type": "Blur",
    "_meta": {
      "title": "Blur"
    }
  },
  "93": {
    "inputs": {
      "image": ["37", 0]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "ðŸ”§ Get Image Size"
    }
  }
}
